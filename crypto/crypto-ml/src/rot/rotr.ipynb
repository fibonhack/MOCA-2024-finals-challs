{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mrcgg\\anaconda3\\envs\\ML-pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "device = \"cuda\"\n",
    "device = torch.device(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# 32 bit rotate left and right\n",
    "def rotl(x, k):\n",
    "    return ((x << k) & 0xFFFFFFFF) | (x >> (32 - k))\n",
    "\n",
    "def rotr(x, k):\n",
    "    return (x >> k) | ((x << (32 - k) & 0xFFFFFFFF))\n",
    "\n",
    "assert rotl(0b1100, 1) == 0b11000\n",
    "assert rotr(0b1100, 1) == 0b0110\n",
    "assert rotl(2**31, 1) == 1\n",
    "assert rotr(1, 1) == 2**31\n",
    "assert rotr(1, 10) == rotl(1, 22)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "noise = 0.0\n",
    "noise_n = 1\n",
    "\n",
    "train_data = []\n",
    "\n",
    "# every rotation is possible using only k=1\n",
    "\n",
    "rot = 1\n",
    "\n",
    "while len(train_data) < 100000:\n",
    "    i = torch.randint(0, 2**32, (1,)).item()\n",
    "    for _ in range(noise_n):\n",
    "        res = torch.tensor([float(a) for a in bin(rotr(i, rot))[2:].rjust(32,\"0\")], dtype=torch.float32)\n",
    "        res = res.to(device)\n",
    "\n",
    "        b = torch.tensor([float(a) for a in bin(i)[2:].rjust(32,\"0\")], dtype=torch.float32)\n",
    "        b += (torch.FloatTensor(32).uniform_(-noise, +noise))\n",
    "        b = b.to(device)\n",
    "\n",
    "        train_data.append((b,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0.,\n",
       "         0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        device='cuda:0'),\n",
       " tensor([0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "         0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for x,y in train_data:\n",
    "#     if x.shape != torch.Size([32+5]):\n",
    "#         print(x.shape)\n",
    "#         print(x,y)\n",
    "#         break\n",
    "#     if y.shape != torch.Size([32]):\n",
    "#         print(y.shape)\n",
    "#         print(x, y)\n",
    "#         break\n",
    "train_data[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "def get_loaders(train_data, device=device):\n",
    "    test_size = 0.05\n",
    "    valid_size = 0.05\n",
    "    batch_size = 500\n",
    "    num_workers = 0\n",
    "\n",
    "    #cuda or cpu\n",
    "    device = torch.device(device)\n",
    "\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(test_size * num_train))\n",
    "    split2 = int(np.floor((valid_size+test_size) * num_train))\n",
    "    train_idx, valid_idx, test_idx = indices[split2:], indices[split:split2], indices[:split]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "    # prepare data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
    "    valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
    "    test_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=test_sampler, num_workers=num_workers)\n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_loaders(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def noise_to_int(bits):\n",
    "    bits = [round(float(b)) for b in bits]\n",
    "    bits = \"\".join([str(b) if b in [0,1] else \"0\" if b<1/10**5 else \"1\" for b in bits])\n",
    "    return int(bits,2)\n",
    "\n",
    "def lin_to_tuple_32_5(t):\n",
    "    a = (t[:32],t[32:])\n",
    "    return tuple([noise_to_int(b) for b in a])\n",
    "\n",
    "def lin_to_list(t):\n",
    "    res = []\n",
    "    for i in range(len(t)//8):\n",
    "        res += [noise_to_int(t[i*8:i*8+8])]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "X, Y = next(iter(train_loader))\n",
    "\n",
    "for x,y in zip(X,Y):\n",
    "    b = noise_to_int(x)\n",
    "    res = noise_to_int(y)\n",
    "    # print(bin(b),k,bin(res))\n",
    "    # print(x)\n",
    "    # print(y)\n",
    "    b1 = rotr(b,1)\n",
    "    assert res == b1\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class RotR(nn.Module):\n",
    "    def __init__(self):     \n",
    "        super(RotR, self).__init__()   \n",
    "        self.body = nn.Sequential(\n",
    "            nn.Linear(32,32),\n",
    "            # nn.Sigmoid(),\n",
    "            # nn.Linear(100,32),\n",
    "            # nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(save_file, model, criterion, train_loader, valid_loader, optimizer=None, n_epochs = 100000, f=noise_to_int, lrate=0.005):\n",
    "    # number of epochs to train the model\n",
    "\n",
    "    if optimizer is None:\n",
    "        # specify optimizer (stochastic gradient descent) and learning rate = 0.001\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lrate)#, weight_decay=0.00000001)\n",
    "\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf # set initial \"min\" to infinity\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # monitor training loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        results = 0\n",
    "        results_n = 0\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train() # prep model for training\n",
    "        i=0\n",
    "        for X, target in train_loader:\n",
    "            i+=1\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            target = target.to(device)\n",
    "            output = model(X)\n",
    "            # calculate the loss\n",
    "            # print(output)\n",
    "            # print(target)\n",
    "            loss = criterion(output, target) #\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update running training loss\n",
    "            train_loss += loss.item()*X.size(0)\n",
    "            if epoch%100 == 0:\n",
    "                for x,y in zip(output,target):\n",
    "                    # print(x.cpu().detach().numpy(),y)\n",
    "                    a = f(x.cpu().detach().numpy())\n",
    "                    # a = int(x[0])\n",
    "                    b = f(y.cpu().detach().numpy())\n",
    "                    # b = int(y[0])\n",
    "                    # a = noise_to_int(x)\n",
    "                    # b = noise_to_int(y)\n",
    "                    \n",
    "                    \n",
    "                    # print(a,b)\n",
    "                    # print(float(x[0]),float(y[0]))\n",
    "                    if a==b:\n",
    "                        \n",
    "                        results +=1\n",
    "                    results_n+=1\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval() # prep model for evaluation\n",
    "        for X, target in valid_loader:\n",
    "        \n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(X)\n",
    "            # target = target.to(device)\n",
    "            # calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "            # update running validation loss\n",
    "            valid_loss += loss.item()*X.size(0)\n",
    "            \n",
    "\n",
    "        # print training/validation statistics\n",
    "        # calculate average loss over an epoch\n",
    "        train_loss = train_loss/len(train_loader.dataset)\n",
    "        valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch+1,\n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "\n",
    "        # save model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "                valid_loss_min,\n",
    "                valid_loss))\n",
    "            torch.save(model.state_dict(), save_file)\n",
    "            valid_loss_min = valid_loss\n",
    "            if train_loss <= 0.000000001:\n",
    "                print(\"stop: loss <= 0.00000\")\n",
    "                return\n",
    "            else:\n",
    "                print(\" loss >= 0.00000\")\n",
    "        \n",
    "        if results_n != 0 :\n",
    "            print(f\"{results/results_n=}\")\n",
    "            print(f\"{results}\")\n",
    "            # if results == results_n and valid_loss <= valid_loss_min:\n",
    "            #     print(\"stop: no errors\")\n",
    "            #     return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.107173 \tValidation Loss: 0.001361\n",
      "Validation loss decreased (inf --> 0.001361).  Saving model ...\n",
      " loss >= 0.00000\n",
      "results/results_n=0.7717444444444445\n",
      "69457\n",
      "Epoch: 2 \tTraining Loss: 0.007521 \tValidation Loss: 0.000046\n",
      "Validation loss decreased (0.001361 --> 0.000046).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 3 \tTraining Loss: 0.000237 \tValidation Loss: 0.000003\n",
      "Validation loss decreased (0.000046 --> 0.000003).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 4 \tTraining Loss: 0.000024 \tValidation Loss: 0.000001\n",
      "Validation loss decreased (0.000003 --> 0.000001).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 5 \tTraining Loss: 0.000004 \tValidation Loss: 0.000000\n",
      "Validation loss decreased (0.000001 --> 0.000000).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 6 \tTraining Loss: 0.000001 \tValidation Loss: 0.000000\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 7 \tTraining Loss: 0.000000 \tValidation Loss: 0.000000\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 8 \tTraining Loss: 0.000000 \tValidation Loss: 0.000000\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 9 \tTraining Loss: 0.000000 \tValidation Loss: 0.000000\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "stop: loss <= 0.00000\n"
     ]
    }
   ],
   "source": [
    "model = RotR().to(device)\n",
    "model.body[0].weight.data.fill_(0.0)\n",
    "model.body[0].bias.data.fill_(0.0)\n",
    "criterion = nn.MSELoss()\n",
    "train(\"rotr.pt\", model, criterion, train_loader, valid_loader, f=noise_to_int, lrate=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RotR().to(device)\n",
    "model.load_state_dict(torch.load(\"rotr.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/results_n=1.0\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "results = 0\n",
    "results_n = 0\n",
    "\n",
    "for X,Y in train_loader:\n",
    "    # print(X,Y)\n",
    "    with torch.no_grad():\n",
    "        O = model(X)\n",
    "    for x,y in zip(O,Y):\n",
    "        a = noise_to_int(x.cpu().detach().numpy())\n",
    "        b = noise_to_int(y.cpu().detach().numpy())\n",
    "        # b = int(y[0]) pos_to_int\n",
    "        # b = noise_to_int(y)\n",
    "        # print(x,y)\n",
    "        # print(a,b)\n",
    "        if a==b:\n",
    "            \n",
    "            results +=1\n",
    "        results_n +=1\n",
    "print(f\"{results/results_n=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/results_n=1.0\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "results = 0\n",
    "results_n = 0\n",
    "\n",
    "for i in range(10000):\n",
    "    x = torch.randint(0, 2**32, (1,)).item()\n",
    "    y = rotr(x,1)\n",
    "    X = torch.tensor([float(a) for a in bin(x)[2:].rjust(32,\"0\")], dtype=torch.float32).to(device)\n",
    "    Y = torch.tensor([float(a) for a in bin(y)[2:].rjust(32,\"0\")], dtype=torch.float32).to(device)\n",
    "    X = X.unsqueeze(0)\n",
    "    Y = Y.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        O = model(X)\n",
    "    for x,y in zip(O,Y):\n",
    "        # print(o,y)\n",
    "        a = noise_to_int(x.cpu().detach().numpy())\n",
    "        b = noise_to_int(y.cpu().detach().numpy())\n",
    "        # b = int(y[0]) pos_to_int\n",
    "        # b = noise_to_int(y)\n",
    "        # print(x,y)\n",
    "        # print(a,b)\n",
    "        if a==b:\n",
    "            \n",
    "            results +=1\n",
    "        results_n +=1\n",
    "print(f\"{results/results_n=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32])\n",
      "torch.Size([32])\n",
      "Parameter containing:\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.body:\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        print(layer.weight.shape)\n",
    "        print(layer.bias.shape)\n",
    "        print(layer.weight)\n",
    "        print(layer.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "state = torch.load(\"rotr.pt\")\n",
    "\n",
    "for w in state[\"body.0.weight\"]:\n",
    "    for i in range(len(w)):\n",
    "        if w[i] > 0:\n",
    "            w[i] = 1.0\n",
    "        else:\n",
    "            w[i] = 0.0\n",
    "\n",
    "for i in range(len(state[\"body.0.bias\"])):\n",
    "    state[\"body.0.bias\"][i] = 0.0\n",
    "torch.save(state,\"rotr.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c4a0582a2f0c696ca3bf144d7a797081d9cfe83a50d52b918de14dcec4b2aff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
