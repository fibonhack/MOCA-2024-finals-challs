{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "device = \"cuda\"\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 0.05\n",
    "noise_n = 1\n",
    "\n",
    "train_data = []\n",
    "for i in range(1000):\n",
    "    b = torch.tensor([i%2], dtype=torch.float32)\n",
    "    b += (torch.FloatTensor(1).uniform_(-noise, +noise))\n",
    "    b = b.to(device)\n",
    "\n",
    "    res = torch.tensor([(i+1)%2], dtype=torch.float32).to(device)\n",
    "    train_data.append((b,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "def get_loaders(train_data, device=device):\n",
    "    test_size = 0.05\n",
    "    valid_size = 0.05\n",
    "    batch_size = 50\n",
    "    num_workers = 0\n",
    "\n",
    "    #cuda or cpu\n",
    "    device = torch.device(device)\n",
    "\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(test_size * num_train))\n",
    "    split2 = int(np.floor((valid_size+test_size) * num_train))\n",
    "    train_idx, valid_idx, test_idx = indices[split2:], indices[split:split2], indices[:split]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "    # prepare data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
    "    valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
    "    test_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=test_sampler, num_workers=num_workers)\n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_loaders(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def noise_to_int(bits):\n",
    "    bits = [round(float(b)) for b in bits]\n",
    "    bits = \"\".join([str(b) if b in [0,1] else \"0\" if b<1/10**5 else \"1\" for b in bits])\n",
    "    return int(bits,2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "X, Y = next(iter(train_loader))\n",
    "\n",
    "for x,y in zip(X,Y):\n",
    "    a = x\n",
    "    b = y\n",
    "    b1 = torch.round(x-1. if x > 0.5 else x+1)\n",
    "    assert b == b1\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "\n",
    "class Norm(nn.Module):\n",
    "    def __init__(self, num_hidden, eps = 1e-6):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.size = num_hidden\n",
    "        \n",
    "        # create two learnable parameters to calibrate normalisation\n",
    "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
    "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
    "        \n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, x):\n",
    "        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n",
    "        / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "        return norm\n",
    "\n",
    "\n",
    "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)\n",
    "    # print(\"scores\",scores.shape)\n",
    "    if mask is not None:\n",
    "        # print(\"mask\",mask.shape)\n",
    "        mask = mask.unsqueeze(1)\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    \n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "    \n",
    "    if dropout is not None:\n",
    "        scores = dropout(scores)\n",
    "    \n",
    "    # print(\"v\",v.shape)\n",
    "    output = torch.matmul(scores, v)\n",
    "    return output\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, num_hidden, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_hidden = num_hidden\n",
    "        self.d_k = num_hidden // heads\n",
    "        self.h = heads\n",
    "        \n",
    "        self.q_linear = nn.Linear(num_hidden, num_hidden)\n",
    "        self.v_linear = nn.Linear(num_hidden, num_hidden)\n",
    "        self.k_linear = nn.Linear(num_hidden, num_hidden)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(num_hidden, num_hidden)\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        \n",
    "        bs = q.size(0)\n",
    "        \n",
    "        # perform linear operation and split into N heads\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
    "        \n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
    "        \n",
    "        # transpose to get dimensions bs * N * sl * num_hidden\n",
    "        k = k.transpose(1,2)\n",
    "        q = q.transpose(1,2)\n",
    "        v = v.transpose(1,2)\n",
    "        \n",
    "\n",
    "        # calculate attention using function we will define next\n",
    "        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "        # concatenate heads and put through final linear layer\n",
    "        concat = scores.transpose(1,2).contiguous()\\\n",
    "        .view(bs, -1, self.num_hidden)\n",
    "        output = self.out(concat)\n",
    "    \n",
    "        return output\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, input_num, output_num, d_ff=2048, dropout = 0.1):\n",
    "        super().__init__() \n",
    "    \n",
    "        # We set d_ff as a default to 2048\n",
    "        self.linear_1 = nn.Linear(input_num, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, output_num)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.linear_1(x)))\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Not(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Not, self).__init__()\n",
    "        \n",
    "        self.body = nn.Sequential(\n",
    "            nn.Linear(1,1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(save_file, model, criterion, train_loader, valid_loader, optimizer=None, n_epochs = 100000, f=noise_to_int, lrate=0.005):\n",
    "    # number of epochs to train the model\n",
    "\n",
    "    if optimizer is None:\n",
    "        # specify optimizer (stochastic gradient descent) and learning rate = 0.001\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lrate)#, weight_decay=0.00000001)\n",
    "\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf # set initial \"min\" to infinity\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # monitor training loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        results = 0\n",
    "        results_n = 0\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train() # prep model for training\n",
    "        i=0\n",
    "        for X, target in train_loader:\n",
    "            i+=1\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            target = target.to(device)\n",
    "            output = model(X)\n",
    "            # calculate the loss\n",
    "            # print(output)\n",
    "            # print(target)\n",
    "            loss = criterion(output, target) #\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update running training loss\n",
    "            train_loss += loss.item()*X.size(0)\n",
    "            if epoch%100 == 0:\n",
    "                for x,y in zip(output,target):\n",
    "                    # print(x.cpu().detach().numpy(),y)\n",
    "                    a = f(x.cpu().detach().numpy())\n",
    "                    # a = int(x[0])\n",
    "                    b = f(y.cpu().detach().numpy())\n",
    "                    # b = int(y[0])\n",
    "                    # a = noise_to_int(x)\n",
    "                    # b = noise_to_int(y)\n",
    "                    \n",
    "                    \n",
    "                    # print(a,b)\n",
    "                    # print(float(x[0]),float(y[0]))\n",
    "                    if np.allclose(a,b, atol=1e-10):\n",
    "                        \n",
    "                        results +=1\n",
    "                    results_n+=1\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval() # prep model for evaluation\n",
    "        for X, target in valid_loader:\n",
    "        \n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(X)\n",
    "            # target = target.to(device)\n",
    "            # calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "            # update running validation loss\n",
    "            valid_loss += loss.item()*X.size(0)\n",
    "            \n",
    "\n",
    "        # print training/validation statistics\n",
    "        # calculate average loss over an epoch\n",
    "        train_loss = train_loss/len(train_loader.dataset)\n",
    "        valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "\n",
    "        print('Epoch: {} \\tTraining Loss: {:.12f} \\tValidation Loss: {:.12f}'.format(\n",
    "            epoch+1,\n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "\n",
    "        # save model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.12f} --> {:.12f}).  Saving model ...'.format(\n",
    "                valid_loss_min,\n",
    "                valid_loss))\n",
    "            torch.save(model.state_dict(), save_file)\n",
    "            valid_loss_min = valid_loss\n",
    "            if train_loss <= 1e-12:\n",
    "                print(\"stop: loss <= 0.00000\")\n",
    "                return\n",
    "            else:\n",
    "                print(\" loss >= 0.00000\")\n",
    "        \n",
    "        if results_n != 0 :\n",
    "            print(f\"{results/results_n=}\")\n",
    "            print(f\"{results}\")\n",
    "            # if results == results_n and valid_loss <= valid_loss_min:\n",
    "            #     print(\"stop: no errors\")\n",
    "            #     return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (inf --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "results/results_n=0.44222222222222224\n",
      "398\n",
      "Epoch: 2 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 3 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 4 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 5 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 6 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 7 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 8 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 9 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 10 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 11 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 12 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 13 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 14 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 15 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 16 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 17 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 18 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 19 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 20 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 21 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 22 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 23 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 24 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 25 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 26 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 27 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 28 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 29 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 30 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 31 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 32 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 33 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 34 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 35 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 36 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 37 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 38 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 39 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 40 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 41 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 42 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 43 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 44 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 45 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 46 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 47 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 48 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 49 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 50 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 51 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 52 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 53 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 54 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 55 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 56 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 57 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 58 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 59 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 60 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 61 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 62 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 63 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 64 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 65 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 66 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 67 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 68 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 69 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 70 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 71 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 72 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 73 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 74 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 75 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 76 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 77 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 78 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 79 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 80 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 81 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 82 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 83 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 84 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 85 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 86 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 87 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 88 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 89 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 90 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 91 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 92 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 93 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 94 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 95 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 96 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 97 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 98 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 99 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 100 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 101 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "results/results_n=0.44222222222222224\n",
      "398\n",
      "Epoch: 102 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 103 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 104 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 105 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 106 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 107 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 108 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 109 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 110 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 111 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 112 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 113 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 114 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 115 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 116 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 117 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 118 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 119 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 120 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 121 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 122 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 123 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 124 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 125 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 126 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 127 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 128 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 129 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 130 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 131 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 132 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 133 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 134 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 135 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 136 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 137 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 138 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 139 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 140 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 141 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 142 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 143 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 144 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 145 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 146 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 147 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 148 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 149 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 150 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 151 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 152 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 153 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 154 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 155 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 156 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 157 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 158 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 159 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 160 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 161 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 162 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 163 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 164 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 165 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 166 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 167 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 168 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 169 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 170 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 171 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 172 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 173 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 174 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 175 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 176 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 177 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 178 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 179 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 180 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 181 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 182 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 183 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 184 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 185 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 186 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 187 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 188 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 189 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 190 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 191 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 192 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 193 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 194 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 195 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 196 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 197 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 198 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 199 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 200 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 201 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "results/results_n=0.44222222222222224\n",
      "398\n",
      "Epoch: 202 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 203 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 204 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 205 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 206 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 207 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 208 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 209 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 210 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 211 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 212 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 213 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 214 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 215 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 216 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 217 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 218 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 219 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 220 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 221 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 222 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 223 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 224 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 225 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 226 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 227 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 228 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 229 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 230 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 231 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 232 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 233 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 234 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 235 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 236 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 237 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 238 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 239 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 240 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 241 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 242 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 243 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 244 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 245 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 246 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 247 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 248 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 249 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 250 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 251 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 252 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 253 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 254 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 255 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 256 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 257 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 258 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 259 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 260 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 261 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 262 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 263 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 264 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 265 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 266 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 267 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 268 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 269 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 270 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 271 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 272 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 273 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 274 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 275 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 276 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 277 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 278 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 279 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 280 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 281 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 282 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 283 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 284 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 285 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 286 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 287 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 288 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 289 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 290 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 291 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 292 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 293 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 294 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 295 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 296 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 297 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 298 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 299 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 300 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 301 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "results/results_n=0.44222222222222224\n",
      "398\n",
      "Epoch: 302 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 303 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 304 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 305 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 306 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 307 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 308 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 309 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 310 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 311 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 312 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 313 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 314 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 315 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 316 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 317 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 318 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 319 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 320 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 321 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 322 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 323 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 324 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 325 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 326 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 327 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 328 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 329 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 330 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 331 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 332 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 333 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 334 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 335 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 336 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 337 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 338 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 339 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 340 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 341 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 342 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 343 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 344 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 345 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 346 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 347 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 348 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 349 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 350 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 351 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 352 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 353 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 354 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 355 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 356 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 357 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 358 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 359 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 360 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 361 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 362 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 363 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 364 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 365 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 366 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 367 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 368 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 369 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 370 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 371 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 372 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 373 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 374 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 375 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 376 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 377 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 378 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 379 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 380 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 381 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 382 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 383 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 384 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 385 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 386 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 387 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 388 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 389 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 390 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 391 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 392 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 393 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 394 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 395 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 396 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 397 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 398 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 399 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 400 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 401 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "results/results_n=0.44222222222222224\n",
      "398\n",
      "Epoch: 402 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 403 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 404 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 405 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 406 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 407 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 408 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 409 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 410 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 411 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 412 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 413 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 414 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 415 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 416 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 417 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 418 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 419 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 420 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 421 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 422 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 423 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 424 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 425 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 426 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 427 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 428 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 429 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 430 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 431 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 432 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 433 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 434 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 435 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 436 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 437 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 438 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 439 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 440 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 441 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 442 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 443 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 444 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 445 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 446 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 447 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 448 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 449 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 450 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 451 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 452 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 453 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 454 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 455 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 456 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 457 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 458 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 459 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 460 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 461 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 462 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 463 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 464 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 465 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 466 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 467 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 468 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 469 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 470 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 471 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 472 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 473 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 474 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 475 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 476 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 477 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 478 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 479 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 480 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 481 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 482 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 483 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 484 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 485 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 486 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 487 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 488 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 489 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 490 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 491 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 492 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 493 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 494 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 495 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 496 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 497 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 498 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 499 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 500 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 501 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "results/results_n=0.44222222222222224\n",
      "398\n",
      "Epoch: 502 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 503 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 504 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 505 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 506 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 507 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 508 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 509 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 510 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 511 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 512 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 513 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 514 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 515 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 516 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 517 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 518 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 519 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 520 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 521 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 522 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 523 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 524 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 525 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 526 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 527 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 528 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 529 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 530 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 531 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 532 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 533 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 534 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 535 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 536 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 537 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 538 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 539 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 540 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 541 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 542 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 543 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 544 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 545 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 546 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 547 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 548 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 549 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 550 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 551 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 552 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 553 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 554 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 555 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 556 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 557 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 558 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 559 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 560 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 561 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 562 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 563 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 564 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 565 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 566 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 567 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 568 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 569 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 570 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 571 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 572 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 573 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 574 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 575 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 576 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 577 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 578 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 579 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 580 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 581 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 582 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 583 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 584 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 585 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 586 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 587 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 588 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 589 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 590 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 591 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 592 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 593 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 594 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Epoch: 595 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 596 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n",
      "Validation loss decreased (0.000000000002 --> 0.000000000002).  Saving model ...\n",
      " loss >= 0.00000\n",
      "Epoch: 597 \tTraining Loss: 0.000000000028 \tValidation Loss: 0.000000000002\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mj:\\Il mio Drive\\CC\\crypto\\vettocon\\AES-ML\\not\\not.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/j%3A/Il%20mio%20Drive/CC/crypto/vettocon/AES-ML/not/not.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# model = Not().to(device)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/j%3A/Il%20mio%20Drive/CC/crypto/vettocon/AES-ML/not/not.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/j%3A/Il%20mio%20Drive/CC/crypto/vettocon/AES-ML/not/not.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train(\u001b[39m\"\u001b[39;49m\u001b[39mnot.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m, model, criterion, train_loader, valid_loader, f\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m x:x, lrate\u001b[39m=\u001b[39;49m\u001b[39m0.00005\u001b[39;49m)\n",
      "\u001b[1;32mj:\\Il mio Drive\\CC\\crypto\\vettocon\\AES-ML\\not\\not.ipynb Cell 12\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(save_file, model, criterion, train_loader, valid_loader, optimizer, n_epochs, f, lrate)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/j%3A/Il%20mio%20Drive/CC/crypto/vettocon/AES-ML/not/not.ipynb#X33sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m model\u001b[39m.\u001b[39mtrain() \u001b[39m# prep model for training\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/j%3A/Il%20mio%20Drive/CC/crypto/vettocon/AES-ML/not/not.ipynb#X33sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m i\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/j%3A/Il%20mio%20Drive/CC/crypto/vettocon/AES-ML/not/not.ipynb#X33sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mfor\u001b[39;00m X, target \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/j%3A/Il%20mio%20Drive/CC/crypto/vettocon/AES-ML/not/not.ipynb#X33sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     i\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/j%3A/Il%20mio%20Drive/CC/crypto/vettocon/AES-ML/not/not.ipynb#X33sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m# clear the gradients of all optimized variables\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mrcgg\\anaconda3\\envs\\ML-pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\mrcgg\\anaconda3\\envs\\ML-pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    569\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    572\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32mc:\\Users\\mrcgg\\anaconda3\\envs\\ML-pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 52\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\mrcgg\\anaconda3\\envs\\ML-pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:172\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    169\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 172\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\mrcgg\\anaconda3\\envs\\ML-pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:172\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    169\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 172\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\mrcgg\\anaconda3\\envs\\ML-pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:138\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    136\u001b[0m         storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_new_shared(numel)\n\u001b[0;32m    137\u001b[0m         out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[1;32m--> 138\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n\u001b[0;32m    139\u001b[0m \u001b[39melif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstr_\u001b[39m\u001b[39m'\u001b[39m \\\n\u001b[0;32m    140\u001b[0m         \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstring_\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mndarray\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmemmap\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    142\u001b[0m         \u001b[39m# array of string classes and object\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = Not().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "train(\"not.pt\", model, criterion, train_loader, valid_loader, f=lambda x:x, lrate=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Not().to(device)\n",
    "model.load_state_dict(torch.load(\"not.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.] [0.]\n",
      "[1.] [1.]\n",
      "[0.] [0.]\n",
      "[1.] [1.]\n",
      "[1.] [1.]\n",
      "[1.] [1.]\n",
      "[1.] [1.]\n",
      "[1.] [1.]\n",
      "[0.] [0.]\n",
      "[1.] [1.]\n",
      "[1.] [1.]\n",
      "[1.] [1.]\n",
      "[0.] [0.]\n",
      "[1.] [1.]\n",
      "[1.] [1.]\n",
      "[0.] [0.]\n",
      "[1.] [1.]\n",
      "[0.] [0.]\n",
      "[0.] [0.]\n",
      "[1.] [1.]\n",
      "[1.] [1.]\n",
      "[1.] [1.]\n",
      "[1.] [1.]\n",
      "[1.] [1.]\n",
      "[0.] [0.]\n",
      "[0.] [0.]\n",
      "[1.] [1.]\n",
      "[0.] [0.]\n",
      "[0.] [0.]\n",
      "[0.] [0.]\n",
      "[0.] [0.]\n",
      "[1.] [1.]\n",
      "[1.] [1.]\n",
      "[1.] [1.]\n",
      "[0.] [0.]\n",
      "[0.] [0.]\n",
      "[0.] [0.]\n",
      "[0.] [0.]\n",
      "[0.] [0.]\n",
      "[0.] [0.]\n",
      "[1.] [1.]\n",
      "[1.] [1.]\n",
      "[0.] [0.]\n",
      "[0.] [0.]\n",
      "[0.] [0.]\n",
      "[1.] [1.]\n",
      "[1.] [1.]\n",
      "[0.] [0.]\n",
      "[0.] [0.]\n",
      "[0.] [0.]\n",
      "results/results_n=1.0\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "X, Y = next(iter(train_loader))\n",
    "\n",
    "# print(X,Y)\n",
    "results = 0\n",
    "results_n = 0\n",
    "O = model(X)\n",
    "for x,y in zip(O,Y):\n",
    "    a = x.cpu().detach().numpy()\n",
    "    b = y.cpu().detach().numpy()\n",
    "    # b = int(y[0]) pos_to_int\n",
    "    # b = noise_to_int(y)\n",
    "    # print(x,y)\n",
    "    print(a,b)\n",
    "    \n",
    "    if np.allclose(a,b,atol=1e-12):\n",
    "        \n",
    "        results +=1\n",
    "    results_n +=1\n",
    "print(f\"{results/results_n=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 1000 mix columns\n",
      "results/results_n=1.0\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "X, Y = next(iter(train_loader))\n",
    "\n",
    "# print(X,Y)\n",
    "results = 0\n",
    "results_n = 0\n",
    "O = X\n",
    "n = 1000\n",
    "for i in range(n):\n",
    "    O = model(O)\n",
    "for x,y in zip(X,O):\n",
    "    # print(x,y)\n",
    "    a = x.cpu().detach().numpy()\n",
    "    b = y.cpu().detach().numpy()\n",
    "    # b = int(y[0]) pos_to_int\n",
    "    # b = noise_to_int(y)\n",
    "    # print(a,b)\n",
    "    r = a\n",
    "    for i in range(n):\n",
    "        r = np.round(r-1.0 if r > 0.5 else r+1)\n",
    "    if np.allclose(r,b,atol=1e-12):\n",
    "        \n",
    "        results +=1\n",
    "    results_n +=1\n",
    "print(f\"after {n} mix columns\")\n",
    "print(f\"{results/results_n=}\")\n",
    "# print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('body.0.weight', tensor([[-10000000.]], device='cuda:0')), ('body.0.bias', tensor([5000000.], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "state = torch.load(\"not.pt\")\n",
    "\n",
    "for w in state[\"body.0.weight\"]:\n",
    "    for i in range(len(w)):\n",
    "        if w[i] < 0:\n",
    "            w[i] = -10000000.0\n",
    "        else:\n",
    "            w[i] = 0.0\n",
    "\n",
    "for i in range(len(state[\"body.0.bias\"])):\n",
    "    state[\"body.0.bias\"][i] = 5000000.0\n",
    "torch.save(state,\"not.pt\")\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c4a0582a2f0c696ca3bf144d7a797081d9cfe83a50d52b918de14dcec4b2aff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
